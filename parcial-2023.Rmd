---
title: "Parcial-2023"
output: html_document
---

**Entrega:** 10 de octubre antes de las 16:00 horas, por correo electrónico con 
el título fundamentos-parcial, un solo documento (pdf/html) por equipo.

**Instrucciones:**

* Tus respuestas deben ser claras y debes explicar 
los resultados, incluye también tus procedimientos/código de manera ordenada, 
y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas, 
...), revisa la sección de visualización en las notas.

* Se puede realizar individual o en parejas.

* Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, error=TRUE, message = FALSE)
library(tidyverse)
library(dplyr)
```

## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A).

Nos dan el siguiente conjunto de datos:

```{r}
zapatos <- read_csv("datos/zapatos-1.csv")
zapatos
```
```{r}
# Convertimos material a factor
zapatos <- zapatos %>%
mutate(material = case_when(
    material == 1 ~ "A",
    material == 2 ~ "B",
    TRUE ~ as.character(material)  # Mantener otros valores como están
  ))
zapatos
```

1. Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el
nivel de significancia de la prueba?).
`
```{r}

# Graficamos la distribución de los desgastes por material
ggplot(zapatos, aes(x = material, y = desgaste)) +
  geom_boxplot(aes(fill = material), alpha = 0.5) +
  geom_jitter(aes(fill = material), alpha = 0.5) +
  labs(title = "Distribución del desgaste por material",
       x = "Material",
       y = "Desgaste") +
  facet_wrap(~ material)
```
```{r}

library(ggplot2)

# Gráfico de densidad para Material A
ggplot(zapatos[zapatos$material == "A", ], aes(x = desgaste)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Densidad de desgaste para Material A")

# Gráfico de densidad para Material B
ggplot(zapatos[zapatos$material == "B", ], aes(x = desgaste)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Densidad de desgaste para Material B")

# Histograma para Material A
ggplot(zapatos[zapatos$material == "A", ], aes(x = desgaste)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.5) +
  labs(title = "Histograma de desgaste para Material A")

# Histograma para Material B
ggplot(zapatos[zapatos$material == "B", ], aes(x = desgaste)) +
  geom_histogram(binwidth = 1, fill = "red", alpha = 0.5) +
  labs(title = "Histograma de desgaste para Material B")

# Gráfico Q-Q para Material A
qqnorm(zapatos$desgaste[zapatos$material == "A"], col = "blue")
qqline(zapatos$desgaste[zapatos$material == "A"], col = "blue")

# Gráfico Q-Q para Material B
qqnorm(zapatos$desgaste[zapatos$material == "B"], col = "red")
qqline(zapatos$desgaste[zapatos$material == "B"], col = "red")

```


```{r}
# Prueba de Shapiro-Wilk para material A
shapiro_test_A <- shapiro.test(zapatos$desgaste[zapatos$material == "A"])
shapiro_test_A

# Prueba de Shapiro-Wilk para material B
shapiro_test_B <- shapiro.test(zapatos$desgaste[zapatos$material == "B"])
shapiro_test_B


```
Los valores de p (p-values) son altos  (alpha generalmente = 0.05), lo que indica que no hay suficiente evidencia para rechazar la hipótesis nula (H0) de que los datos de desgaste para los materiales A y B siguen una distribución normal o no difieren significativamente de una distribución normal.


```{r}
# Prueba de igualdad de varianzas (Prueba de Levene)
library(car)  # Cargar la librería necesaria

levene_test_result <- leveneTest(desgaste ~ material, data = zapatos)
levene_test_result

# Prueba t de Student para comparar las medias
t_test_result <- t.test(desgaste ~ material, data = zapatos, var.equal = TRUE)
t_test_result

```
Prueba de Igualdad de Varianzas (Prueba de Levene):

Estadístico de prueba F = 0.0113
Valor p = 0.9166
*Resultado*: No hay evidencia suficiente para rechazar la hipótesis nula de igualdad de varianzas entre los materiales A y B. Esto indica que se cumple el supuesto de igualdad de varianzas.

Prueba t de Student:

Estadístico t = -0.36891
Grados de libertad (df) = 18
Valor p = 0.7165

*Resultado:* No hay evidencia suficiente para rechazar la hipótesis nula de que las medias de desgaste son iguales entre los materiales A y B.No hay diferencias significativas en las medias de desgaste entre los materiales A y B.

Los datos de desgaste para los materiales A y B muestran igualdad de varianzas y no muestran diferencias significativas en las medias de desgaste. Por lo tanto, los dos materiales parecen comportarse de manera similar en términos de desgaste.



2. Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.

```{r}
# Cargamos las bibliotecas necesarias
library(readr)
library(dplyr)
library(ggplot2)


# Calculamos la diferencia observada entre los materiales A y B
diferencia_obs <- zapatos %>%
  group_by(material) %>%
  summarise(media_desgaste = mean(desgaste)) %>%
  arrange(material) %>%
  pull(media_desgaste) %>%
  diff()

# Creamos una función para realizar la prueba del lineup
lineup_test <- function(data, n_perm = 10000) {
  set.seed(123) # Establecemos una semilla para reproducibilidad
  obs_stat <- abs(diff(data))
  perm_stats <- replicate(n_perm, {
    permuted_data <- sample(data) # Permutamos los datos
    perm_stat <- abs(diff(permuted_data))
    perm_stat
  })
  
  p_value <- mean(perm_stats >= obs_stat)
  return(p_value)
}

# Realizamos la prueba de hipótesis visual
n_permutations <- 10000
p_value <- lineup_test(zapatos$desgaste, n_permutations)

# Nivel de significancia de la prueba
alpha <- 0.05

# Evaluamos si rechazamos o no la hipótesis nula
if (p_value <= alpha) {
  conclusion <- "Rechazamos la hipótesis nula"
} else {
  conclusion <- "No tenemos suficiente evidencia para rechazar la hipótesis nula"
}

# Imprimimos los resultados
cat("Diferencia observada entre A y B:", diferencia_obs, "\n")
cat("Valor p (nivel de significancia):", p_value, "\n")
cat("Conclusión:", conclusion, "\n")
```

La diferencia observada entre los materiales A y B es de 0.41 unidades, lo que significa que los zapatos hechos con el material A tienen un desgaste 0.41 unidades mayor que los zapatos hechos con el material B. Sin embargo, el valor p calculado es de 0.66, que es mayor que el nivel de significancia establecido en 0.05. Esto significa que es más probable que la diferencia observada sea debida al azar que a una diferencia real entre los dos materiales.
Los dos materiales parecen ser comparables en desgaste de zapatos. la diferencia observada sea debida al azar.




3. Después de discutir con los responsables del proyecto descubrimos que nos 
faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de sus zapatos y el otro material al otro zapato de cada niño.
¿Cómo incorporas esta información en tu prueba de hipótesis del inciso 2? ¿Cambian
tus conclusiones?

```{r}
zapatos2 <- read_csv("datos/zapatos-2.csv")
zapatos2
```

sí hay repercusiones en el diseño del estudio. 

Hipótesis Nula
H0: No hay diferencia en las diferencias de desgaste entre los materiales A y B cuando se comparan los dos zapatos de cada niño.

Hipótesis Alternativa (actualizada):
H1: Hay una diferencia en las diferencias de desgaste entre los materiales A y B cuando se comparan los dos zapatos de cada niño.
Luego, procedemos a realizar la prueba de permutaciones como en el  inciso 2, pero esta vez, evaluando las diferencias en lugar de las medias directamente. 
la función "lineup_test" y el procedimiento general se mantendrán similares, pero permutando las diferencias de desgaste en lugar de los valores de desgaste individuales.

```{r}
# Calculamos la diferencia observada entre los materiales A y B
diferencia_obs <- zapatos2 %>%
  group_by(material) %>%
  summarise(media_desgaste = mean(desgaste)) %>%
  arrange(material) %>%
  pull(media_desgaste) %>%
  diff()

# Creamos una función para realizar la prueba de permutaciones para diferencias
lineup_test_diferencias <- function(data, n_perm = 10000) {
  set.seed(123) # Establecemos una semilla para reproducibilidad
  obs_stat <- abs(diff(data))
  perm_stats <- replicate(n_perm, {
    permuted_data <- sample(data) # Permutamos las diferencias
    perm_stat <- abs(diff(permuted_data))
    perm_stat
  })
  
  p_value <- mean(perm_stats >= obs_stat)
  return(p_value)
}

# Realizamos la prueba de hipótesis visual para diferencias
n_permutations <- 10000
p_value <- lineup_test_diferencias(zapatos$desgaste, n_permutations)

# Nivel de significancia de la prueba
alpha <- 0.05

# Evaluamos si rechazamos o no la hipótesis nula
if (p_value <= alpha) {
  conclusion <- "Rechazamos la hipótesis nula"
} else {
  conclusion <- "No tenemos suficiente evidencia para rechazar la hipótesis nula"
}

# Imprimimos los resultados
cat("Diferencia observada entre A y B:", diferencia_obs, "\n")
cat("Valor p (nivel de significancia):", p_value, "\n")
cat("Conclusión:", conclusion, "\n")
```
No hay suficiente evidencia para rechazar la hipótesis nula. No se encontró diferencia significativa en el desgaste entre los materiales A y B cuando se comparan los dos zapatos de cada niño
No es posible concluir que haya una diferencia significativa en el desgaste entre los materiales A y B después de considerar el diseño emparejado de los datos.


## Bootstrap

#### Antecedentes 

En México, las elecciones tienen lugar un domingo, los resultados oficiales 
del proceso se presentan a la población una semana después. A fin de evitar 
proclamaciones de victoria injustificadas durante ese periodo el INE organiza un 
conteo rápido. Un conteo rápido es un procedimiento para estimar, a partir de una muestra 
aleatoria de casillas, el porcentaje de votos a favor de cada opción en la boleta. 

En 2021 se realizó un conteo rápido para estimar los resultados de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/) y en los siguientes
incisos estimarán los resultados de la consulta y evaluation methodology metodología. 

##### Diseño de la muestra

El diseño utilizado en los conteos rápidos es *muestreo estratificado simple*, 
es decir:

i) se particionan las casillas de la pablación en estratos (cada casilla
pertenece a exactamente un estrato), y 

ii) dentro de cada estrato se usa *muestreo aleatorio* para seleccionar las 
casillas que estarán en la muestra. 

##### Estimación 

Una de las metodolgías de estimación, que se usa en el conteo rápido (tanto de 
elecciones como en consultas) es *estimador de razón combinado*, con
intervalos de 95% de confianza construidos con el método normal y error 
estándar bootstrap. En este ejercicio debes construir intervalos usando este 
procedimiento.

Para cada opción en la consulta (sí/no/nulos) usarás la muestra del conteo rápido
para estimar los resultados de la consulta.

1. Calcula el estimador de razón combinado, para muestreo estratificado la 
fórmula es:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
  donde:

  * $\hat{p}$ es la estimación de la proporción de votos que recibió la opción (ej: *sí*).

  * $Y_{hi}$ es el número total de votos que recibió *la opción* (ej: *sí*)
en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

  * $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al 
$h$-ésimo estrato. 

  * $N_h$ es el número total de casillas en el $h$-ésimo estrato.

  * $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en 
la muestra.


##### Datos 

Necesitarás los siguientes datos:

* Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

* Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r}
# preprocesamiento de tablas de datos
computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5)
computos <- computos |> 
  rename(ID = CLAVE_MRCP) |> 
  mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                         str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
         LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
         TOTAL = TOTAL_OPINIONES)

muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) 
muestra_tidy <- muestra |> 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) |> 
  group_by(ESTRATO) |> 
  mutate(n = n()) |> 
  ungroup()
muestra
```
```{r}
# Lista de opciones a calcular
opciones <- c("SI", "NO", "NULOS")

# Función para calcular el estimador de razón combinado
calcular_estimador_razon_combinado <- function(datos, opcion) {
  Y_hi <- sum(datos[[opcion]]) # Ajusta la columna según la opción
  X_hi <- sum(datos[["TOTAL"]]) # Ajusta la columna según la opción
  
  # Calcular el estimador utilizando la fórmula adecuada
  estimador <- Y_hi / X_hi
  return(estimador)
}

# Inicializar una lista para almacenar los resultados
resultados_lista <- list()

# Calcular el estimador de razón combinado para cada opción
for (opcion in opciones) {
  # Filtrar los datos de muestra para la opción actual
  datos_opcion <- muestra_tidy %>%
    filter(get(opcion) == 1)
  
  # Calcular el estimador de razón combinado
  estimador_opcion <- calcular_estimador_razon_combinado(datos_opcion, opcion)
  
  # Almacenar el resultado en la lista
  resultados_lista[[opcion]] <- estimador_opcion
}

# Imprimir los resultados
for (opcion in opciones) {
  cat("Estimador de razón combinado para", opcion, ":", resultados_lista[[opcion]], "\n")
}
```


2. Utiliza **bootstrap** para calcular el error estándar, y reporta tu 
estimación del error.
    + Genera 1000 muestras bootstrap.
    + Recuerda que las muestras bootstrap tienen que tomar en cuenta la 
    metodología que se utilizó en la selección de la muestra original, en este
    caso implica que para cada remuestra debes tomar muestra aleatoria independiente
    dentro de cada estrato.
    
```{r}
# Establecer una semilla para reproducibilidad
set.seed(240589)

# Función para realizar el muestreo bootstrap
sample_bootstrap <- function(data) {
  n <- nrow(data)
  indices <- sample(1:n, n, replace = TRUE)
  muestra_bootstrap <- data[indices, ]
  return(muestra_bootstrap)
}

# Función para calcular el estimador de razón combinado
calcular_estimador_razon_combinado <- function(datos, opcion) {
  Y_hi <- sum(datos[[opcion]]) # Ajusta la columna según la opción
  X_hi <- sum(datos[["TOTAL"]]) # Ajusta la columna según la opción
  
  # Calcular el estimador utilizando la fórmula adecuada
  estimador <- Y_hi / X_hi
  return(estimador)
}

# Función para realizar el bootstrap y calcular el error estándar
calcular_bootstrap_se <- function(datos, opcion, num_muestras = 1000) {
  muestras <- replicate(num_muestras, {
    # Realizar el muestreo bootstrap utilizando la función sample_bootstrap
    muestra_bootstrap <- sample_bootstrap(datos)
    
    # Calcular el estimador de razón combinado para la opción actual
    estimador_opcion <- calcular_estimador_razon_combinado(muestra_bootstrap, opcion)
    
    return(estimador_opcion)
  })
  
  # Calcular el error estándar
  bootstrap_se <- sd(muestras, na.rm = TRUE)
  return(bootstrap_se)
}

# Inicializar una lista para almacenar los errores estándar
errores_estandar_lista <- list()

# Calcular el error estándar utilizando bootstrap para cada opción
for (opcion in opciones) {
  # Filtrar los datos de muestra para la opción actual
  datos_opcion <- muestra_tidy %>%
    filter(get(opcion) == 1)
  
  # Calcular el error estándar utilizando bootstrap
  bootstrap_se <- calcular_bootstrap_se(datos_opcion, opcion)
  
  # Almacenar el resultado en la lista
  errores_estandar_lista[[opcion]] <- bootstrap_se
}

# Imprimir los errores estándar
for (opcion in opciones) {
  cat("Error estándar para", opcion, ":", errores_estandar_lista[[opcion]], "\n")
}
```

3. Construye un intervalo del 95% de confianza utilizando el método normal. Revisa 
si el supuesto de normalidad es razonable.

```{r}
# Error estándar para cada opción
error_estandar_si <- 0.0002490102
error_estandar_no <- 0.0002178224
error_estandar_nulos <- 0.0002178224

# Nivel de confianza del 95%
nivel_confianza <- 0.95

# Calcular los valores críticos de la distribución normal estándar
valor_critico_inferior <- qnorm((1 - nivel_confianza) / 2)
valor_critico_superior <- qnorm((1 + nivel_confianza) / 2)

# Estimaciones para cada opción
estimacion_si <- 0.125
estimacion_no <- 0.009629431
estimacion_nulos <- 0.008026477

# Calcular los límites del intervalo de confianza para cada opción
limite_inferior_si <- estimacion_si - valor_critico_superior * error_estandar_si
limite_superior_si <- estimacion_si + valor_critico_superior * error_estandar_si

limite_inferior_no <- estimacion_no - valor_critico_superior * error_estandar_no
limite_superior_no <- estimacion_no + valor_critico_superior * error_estandar_no

limite_inferior_nulos <- estimacion_nulos - valor_critico_superior * error_estandar_nulos
limite_superior_nulos <- estimacion_nulos + valor_critico_superior * error_estandar_nulos

# Imprimir los intervalos de confianza
cat("Intervalo de confianza del 95% para SI:", limite_inferior_si, "-", limite_superior_si, "\n")
cat("Intervalo de confianza del 95% para NO:", limite_inferior_no, "-", limite_superior_no, "\n")
cat("Intervalo de confianza del 95% para NULOS:", limite_inferior_nulos, "-", limite_superior_nulos, "\n")

```

```{r}
# Verificar si hay NA en los resultados de bootstrap
anyNA( bootstrap_se)

# Resumen de los resultados de bootstrap
summary( bootstrap_se)

```

4. Reporta tus intervalos en una tabla. Compara la longitud de los 3 intervalos y 
describe que observas.

```{r}
# Crear un data frame con los intervalos y opciones
intervalos <- data.frame(
  Opción = c("SI", "NO", "NULOS"),
  Límite_Inferior = c(limite_inferior_si, limite_inferior_no, limite_inferior_nulos),
  Límite_Superior = c(limite_superior_si, limite_superior_no, limite_superior_nulos),
  Longitud = c(limite_superior_si - limite_inferior_si, limite_superior_no - limite_inferior_no, limite_superior_nulos - limite_inferior_nulos)
)
# Imprimir la tabla
print(intervalos)

```

3. ¿Tus intervalos contienen los valores observados en los cómputos? Explica los
resultados observados.

 los valores observados caen dentro de los intervalos de confianza calculados
los valores reales para estas opciones están dentro de estos intervalos
los valores reales están dentro de los límites del intervalo calculado a partir de la muestra de datos


#### Calibración

Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la 
muestra utilizada en el conteo rápido. Esto es, selecciona el 
mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.

* Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.

* Grafica los intervalos y calcula la proporción de ellos que contienen el 
verdadero valor observado. Describe tus observaciones y compara con el intervalo 
obtenido en el ejercicio anterior.

```{r}
# Establecer una semilla para reproducibilidad
set.seed(123)

# Número de muestras a generar
num_samples <- 50

# Tamaño de cada muestra (igual al tamaño de la muestra original)
sample_size <- nrow(muestra_tidy)

# Crear una lista para almacenar los resultados de los intervalos
intervalos_lista <- list()

# Valor crítico para el intervalo de confianza del 95%
valor_critico <- qnorm(0.975)

# Generar las muestras y calcular los intervalos de confianza para cada una
for (i in 1:num_samples) {
  # Realizar el remuestreo bootstrap
  muestra_bootstrap <- sample_bootstrap(muestra_tidy)
  
  # Inicializar una lista para almacenar los resultados de los intervalos para esta muestra
  intervalos_sample <- list()
  
  # Calcular el estimador de razón combinado y el error estándar para cada opción
  for (opcion in opciones) {
    datos_opcion <- muestra_bootstrap %>%
      filter(get(opcion) == 1)
    
    # Calcular el error estándar utilizando bootstrap
    bootstrap_se <- calcular_bootstrap_se(datos_opcion, opcion)
    
    # Calcular los límites del intervalo de confianza para esta opción
    limite_inferior <- resultados_lista[[opcion]] - valor_critico * bootstrap_se
    limite_superior <- resultados_lista[[opcion]] + valor_critico * bootstrap_se
    
    # Almacenar el resultado en la lista de intervalos para esta muestra
    intervalos_sample[[opcion]] <- c(limite_inferior, limite_superior)
  }
  
  # Almacenar la lista de intervalos de esta muestra en la lista principal
  intervalos_lista[[i]] <- intervalos_sample
}

# Imprimir los intervalos para una muestra
for (opcion in opciones) {
  cat("Intervalos de confianza para", opcion, "en una muestra:\n")
  for (i in 1:num_samples) {
    intervalo <- intervalos_lista[[i]][[opcion]]
    cat("Muestra", i, ":", "Límite Inferior =", intervalo[1], "Límite Superior =", intervalo[2], "\n")
  }
  cat("\n")
}
````


#### Análisis Exploratorio

Un voto nulo corresponde a una boleta donde el ciudadano acudió a las urnas
y anuló su voto. 

Antes de contestar los siguiente incisos piensen que rango esperarían ver para la
proporción de votos nulos en una casilla.

La proporción de votos nulos en una casilla depende de múltiples factores, (participación en la votación, la  la comprensión del proceso de votar,  las instrucciones que se dan en las casillas, etc). Puede ocurrir que la mayoría de los votantes emitan un voto válido, por lo que la proporción de votos nulos tiende a ser baja. Pero puede asentuarse en lugaros con contextos socioeconómicos complejos). Esperariamos que oscile entre un valor cercano al 0% y un valor relativamente bajo



* Describe la distribución de datos nulos en la muestra, y como se relaciona con 
el total de votos, realiza gráficas y describe tus observaciones.

```{r}
# Inicializar una lista para almacenar las proporciones de intervalos que contienen los valores observados
proporciones_contenidas <- list()

# Calcular la proporción de intervalos que contienen los valores observados para cada opción
for (opcion in opciones) {
  proporciones <- sapply(intervalos_lista, function(intervalo) {
    valor_observado <- resultados_lista[[opcion]]
    contiene_valor_observado <- valor_observado >= intervalo[[opcion]][1] && valor_observado <= intervalo[[opcion]][2]
    return(contiene_valor_observado)
  })
  
  # Almacenar las proporciones en la lista
  proporciones_contenidas[[opcion]] <- proporciones
}

# Calcular la proporción promedio de intervalos que contienen los valores observados para cada opción
proporciones_promedio <- sapply(opciones, function(opcion) {
  proporciones <- proporciones_contenidas[[opcion]]
  prop_promedio <- mean(proporciones)
  return(prop_promedio)
})

# Imprimir la proporción de intervalos que contienen los valores observados
cat("Proporción de intervalos que contienen los valores observados:\n")
for (opcion in opciones) {
  cat(opcion, ":", proporciones_promedio[opcion], "\n")
}

ggplot(data = muestra_bootstrap, aes(x = NULOS)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Distribución de Votos Nulos",
       x = "Cantidad de Votos Nulos",
       y = "Frecuencia") +
  xlim(0, 50)  # Ajusta el rango del eje x según tu preferencia
ggplot(data = muestra_bootstrap, aes(x = TOTAL, y = NULOS)) +
  geom_point(color = "red") +
  labs(title = "Relación entre Votos Nulos y Total de Votos",
       x = "Total de Votos",
       y = "Cantidad de Votos Nulos")
```

* En la distribución de proporción de nulos se observan datos atípicos, ¿cuál 
crees que sea la razón de estas observaciones extremas? ¿consideras que se
deben eliminar de la muestra antes de realizar la estimación?


